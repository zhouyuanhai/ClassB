{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Set global random seeds for reproducibility\n",
    "SEED = 45\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "# Cell 1: Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "  from tensorflow.keras.optimizers import Adam\n",
    "except ImportError:\n",
    "  from keras.optimizers import Adam\n",
    "\n",
    "print(\"All libraries imported successfully!ÔºÅ\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "path_prefix = \"******\"\n",
    "\n",
    "try:\n",
    "    all_data_pd = pd.read_csv(path_prefix + \"original_data.csv\")\n",
    "\n",
    "    print(\"Original data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Original data file not found. Please check the path!\")\n",
    "\n",
    "# 2. Load the three key CSV files generated in R\n",
    "try:\n",
    "    training_residuals = pd.read_csv(path_prefix + \"training_set_residuals.csv\")\n",
    "    arima_validation_forecasts = pd.read_csv(path_prefix + \"validation_set_predictions.csv\")\n",
    "    arima_final_forecasts = pd.read_csv(path_prefix + \"final_forecast_results.csv\")\n",
    "    print(\"R-generated CSV files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: CSV file not found: {e}. Please check the path!\")"
   ],
   "id": "5460077feafd666",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_dataset(data, time_steps=1):\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "\n",
    "        X.append(data[i:(i + time_steps)])\n",
    "\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "d42d0ad7ba1a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- [Final Complete Version] Cell 4: Includes forced sorting logic and calculates both RMSE and MAE ---\n",
    "\n",
    "# Initialize lists\n",
    "final_results_list = []\n",
    "model_selection_list = []\n",
    "\n",
    "# Hyperparameters\n",
    "TIME_STEPS = 3\n",
    "LSTM_UNITS = 50\n",
    "EPOCHS = 200\n",
    "\n",
    "unique_diseases = all_data_pd['metric2'].unique()\n",
    "\n",
    "for disease in unique_diseases:\n",
    "    if pd.isna(disease):\n",
    "        continue\n",
    "    print(f\"--- Processing disease: {disease} ---\")\n",
    "\n",
    "    try:\n",
    "        # a. Prepare data and force sorting\n",
    "        current_residuals_train_df = training_residuals[training_residuals['metric'] == disease].sort_values(by='time')\n",
    "        current_arima_validation_df = arima_validation_forecasts[arima_validation_forecasts['metric'] == disease].sort_values(by='time')\n",
    "        current_arima_final_df = arima_final_forecasts[arima_final_forecasts['metric'] == disease].sort_values(by='time')\n",
    "\n",
    "        current_residuals_train = current_residuals_train_df['residual'].values\n",
    "        current_arima_validation = current_arima_validation_df['predicted_incidence_rate'].values\n",
    "\n",
    "        if len(current_residuals_train) < TIME_STEPS + 5:\n",
    "            print(\"  >> Insufficient residual data, skipping LSTM modeling.\")\n",
    "            continue\n",
    "\n",
    "        # 2. Create a custom Adam optimizer instance and specify the learning rate\n",
    "        custom_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "        # b. LSTM training (no changes in this part)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        residuals_scaled = scaler.fit_transform(current_residuals_train.reshape(-1, 1))\n",
    "        X_train, y_train = create_dataset(residuals_scaled, TIME_STEPS)\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        lstm_model = Sequential([ LSTM(units=LSTM_UNITS, input_shape=(TIME_STEPS, 1)), Dense(units=1) ])\n",
    "        lstm_model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
    "        lstm_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=1, verbose=0, shuffle=False)\n",
    "\n",
    "        # c. LSTM prediction (no changes in this part)\n",
    "        n_predict = 6\n",
    "        last_known_residuals = residuals_scaled[-TIME_STEPS:]\n",
    "        predicted_residuals_scaled = []\n",
    "        current_input = last_known_residuals.reshape(1, TIME_STEPS, 1)\n",
    "        for _ in range(n_predict):\n",
    "            next_pred = lstm_model.predict(current_input, verbose=0)\n",
    "            predicted_residuals_scaled.append(next_pred[0, 0])\n",
    "            new_input_sequence = np.append(current_input.flatten()[1:], next_pred)\n",
    "            current_input = new_input_sequence.reshape(1, TIME_STEPS, 1)\n",
    "        predicted_residuals = scaler.inverse_transform(np.array(predicted_residuals_scaled).reshape(-1, 1)).flatten()\n",
    "        predicted_validation_residuals = predicted_residuals[0:2]\n",
    "        predicted_final_residuals = predicted_residuals[2:6]\n",
    "\n",
    "        # d. Calculate hybrid model predicted values on the validation set\n",
    "        hybrid_validation_pred = current_arima_validation + predicted_validation_residuals\n",
    "\n",
    "        # e. Calculate RMSE and MAE for both models on the validation set\n",
    "        actual_validation_df = all_data_pd[\n",
    "            (all_data_pd['metric2'] == disease) &\n",
    "            (all_data_pd['time'].between(2018, 2019))\n",
    "        ].sort_values(by='time')\n",
    "        actual_validation_values = actual_validation_df['incidence_rate'].values\n",
    "\n",
    "        if len(actual_validation_values) != 2:\n",
    "            print(f\"  >> Validation set actual data length is not 2, skipping {disease}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate RMSE\n",
    "        arima_mse = mean_squared_error(actual_validation_values, current_arima_validation)\n",
    "        hybrid_mse = mean_squared_error(actual_validation_values, hybrid_validation_pred)\n",
    "        arima_rmse = np.sqrt(arima_mse)\n",
    "        hybrid_rmse = np.sqrt(hybrid_mse)\n",
    "\n",
    "        # [NEW] Calculate MAE (Mean Absolute Error)\n",
    "        arima_mae = mean_absolute_error(actual_validation_values, current_arima_validation)\n",
    "        hybrid_mae = mean_absolute_error(actual_validation_values, hybrid_validation_pred)\n",
    "\n",
    "        # f. Model tournament... (subsequent code unchanged) ...\n",
    "        current_arima_final_df = arima_final_forecasts[arima_final_forecasts['metric'] == disease].sort_values(by='time')\n",
    "\n",
    "        if np.isnan(hybrid_rmse) or arima_rmse <= hybrid_rmse:\n",
    "            winner = \"ARIMA\"\n",
    "            final_prediction = current_arima_final_df.copy()\n",
    "        else:\n",
    "            winner = \"ARIMA-LSTM\"\n",
    "            hybrid_final_prediction_values = current_arima_final_df['predicted_incidence_rate'].values + predicted_final_residuals\n",
    "            final_prediction = current_arima_final_df.copy()\n",
    "            final_prediction['predicted_incidence_rate'] = hybrid_final_prediction_values\n",
    "\n",
    "        # g. Store results\n",
    "        final_prediction['predicted_incidence_rate'] = final_prediction['predicted_incidence_rate'].clip(lower=0)\n",
    "        final_results_list.append(final_prediction)\n",
    "\n",
    "\n",
    "        model_selection_list.append({\n",
    "            'metric': disease,\n",
    "            'ARIMA_RMSE': arima_rmse,\n",
    "            'ARIMA_MAE': arima_mae,\n",
    "            'Hybrid_RMSE': hybrid_rmse,\n",
    "            'Hybrid_MAE': hybrid_mae,\n",
    "            'Selected_Model': winner\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  >> Error occurred while processing {disease}: {e}\")\n",
    "\n",
    "print(\"\\n--- All diseases processed! ---\")"
   ],
   "id": "162edce8ceaf8a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "final_predictions_df = pd.concat(final_results_list, ignore_index=True)\n",
    "model_selection_df = pd.DataFrame(model_selection_list)\n",
    "\n",
    "median_hybrid_rmse = model_selection_df['Hybrid_RMSE'].median()\n",
    "median_hybrid_mae = model_selection_df['Hybrid_MAE'].median()"
   ],
   "id": "d515ebcea504723a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "output_excel_path = \"***/final_prediction_results.xlsx\""
   ],
   "id": "d7616f7842f4b4b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4bc1d70900a20260",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
